{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "private_outputs": true,
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/matt-cornelius/Flip/blob/main/Copy_of_Practical_1_Pytorch_perceptron_ish.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# CSE 40868: Neural Networks - Spring 2025\n",
        "\n",
        "## Practical Session 1 - Single Layer \"Quasi-Perceptrons\"\n",
        "\n",
        "_New: Jan 14, 2025_\n",
        "\n",
        "Logistics:\n",
        " * Using the \"File > Save to Github\" menu above, save a copy of this notebook to your class Github repo. Maks sure you save it  in the `Practicals/Practical1` folder by prepending `Practicals/Practical1/` to the notebook file name.\n",
        " * Study and run the notebook *before class on January 22*.\n",
        " * Arrive in class ready to do some of the work required.\n",
        " * Finish up your work and commit the changes to your repo, and finish the work by 11:59pm on Friday, January 24.\n",
        "\n",
        "[ref](https://machinelearningmastery.com/building-a-single-layer-neural-network-in-pytorch/)\n",
        "\n",
        "\n",
        "This practical session is intended to familiarize you with common idioms of [PyTorch](https://pytorch.org) -- the current dominant approach to neural net design and training.\n",
        "\n",
        "We're going to implement a single-neuron net that will act similarly to a perceptron. PyTorch is overkill for this, but the idioms are mostly here and will transfer right over to your future code.\n",
        "\n",
        "We aren't using GPUs in this notebook.  Supporting them adds a bit of extra stuff that gets in the way of a good understanding on a first exposure.\n",
        "\n",
        "It might be quite useful for you to examine/run a beginner's tutorial from the PyTorch people that addresses a different computer vision problem (classification of clothing items): go [here](https://pytorch.org/tutorials/beginner/basics/quickstart_tutorial.html) for that tutorial."
      ],
      "metadata": {
        "id": "6E8pawEFQPjO"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Prof-provided material"
      ],
      "metadata": {
        "id": "-8CGyQI09aYj"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 1. Import all the things\n",
        "\n",
        "If you add code that needs a new thing to be `import`ed, put it here.\n"
      ],
      "metadata": {
        "id": "zdEHhqayXdBa"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#include all the things\n",
        "import os\n",
        "import numpy as np\n",
        "import gdown\n",
        "import random\n",
        "import matplotlib.pyplot as plt\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torchsummary\n",
        "import tqdm.notebook as tqdm\n"
      ],
      "metadata": {
        "id": "lRJo3AeTOQpq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 2. Initialize the random number generator\n",
        "\n",
        "Initialize the random number generator used by PyTorch. Sometimes you want a repeatable set of random numbers, and PyTorch can do that. We don't need that here.  Just a random initialization is all we need.  The return value is the 64-bit integer used to seed the generator (we assign it to `_` to avoid generating output from the cell)."
      ],
      "metadata": {
        "id": "QVpSkvN2K6Yu"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# \"Sets the seed for generating random numbers to a non-deterministic random number on all devices.\"\n",
        "_ = torch.random.seed()"
      ],
      "metadata": {
        "id": "1w0iTrSSK47g"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 3. Get the data and examine it a bit\n",
        "\n",
        "The code in the cell below, downloads and reads (into a dictionary) a 40MB data file containing a bunch of 128-dimensional data samples from a face recognition experiment using data collected here at ND.\n",
        "\n",
        "The vectors are points in some high-dimensional space, and these vectors are grouped by identity in a `dictionary` -- the `key` is a numerical subject id, and the `value` is a numpy array with 128 columns and N rows, where N is the number of images of the subject."
      ],
      "metadata": {
        "id": "kgyxGpT-tPZq"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# download data from Google Drive using gdown\n",
        "\n",
        "url = 'https://drive.google.com/uc?id=19heLsvTf6AHj9irshCS-zdhTeL-w-Zc7'\n",
        "localname = 'embeddingsbysubject.npy'\n",
        "if os.path.exists(localname):\n",
        "    print(f'{localname} already exists. Delete if you want to re-download it.')\n",
        "else:\n",
        "    gdown.download(url,localname)\n",
        "\n",
        "# load the file\n",
        "# the file contains a numpy array with one element: a ginormous dict.\n",
        "# the .item() method pries the dict out of the array\n",
        "\n",
        "d = np.load(localname,allow_pickle=True).item()\n",
        "\n",
        "# brief examination of the dictionary\n",
        "# a list of keys\n",
        "lkeys = list(d.keys())\n",
        "\n",
        "# a random choice from the list - a subject ID\n",
        "rkey = random.choice(lkeys)\n",
        "print(f'{len(lkeys)} keys present. One of them is {rkey}.')\n",
        "\n",
        "# how many samples for that ID? get the value, it's a numpy array.\n",
        "# look at its shape\n",
        "v = d[rkey]\n",
        "s = d[rkey].shape\n",
        "print(f'd[{rkey}].shape is {s}: {s[0]} samples, each one {s[1]}-dimensional')\n"
      ],
      "metadata": {
        "id": "RYgLSrl_smw9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 4. Define a Pytorch `Dataset` subclass\n",
        "\n",
        "`torch.utils.data.DataSet` is an abstract class in Pytorch for a source of data. You create a subclass that implements `__init__()`, `__len__()`, and `__getitem__()`, which do the obvious things. Most of the action is in the init method, and there are \"patterns\" for file-based data sets, randomly created data sets, (probably) streaming data sets, _etc._\n",
        "\n",
        "Here, we define a `Dataset` subclass named `TwoPersonData` that is tied closely to the data file we just read. It's initialized with the dictionary and two subject-IDs.  As long as the dict is organized this way and the subject-IDs are valid keys, and a numpy array is retrieved when the dict is keyed, then this works.\n"
      ],
      "metadata": {
        "id": "RPnZGsD6vnkt"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Note: we're using a sigmoid for classification so the class labels must be\n",
        "# 0 and 1\n",
        "class TwoPersonData(torch.utils.data.Dataset):\n",
        "    def __init__(self,source,subid0,subid1):\n",
        "        \"\"\"initialize a data set from two entries in a dict with the supplied keys.\"\"\"\n",
        "        self.data = np.vstack([d[subid0],d[subid1]])\n",
        "        self.n0 = d[subid0].shape[0] # number of samples\n",
        "        self.n1 = d[subid1].shape[0] # number of samples\n",
        "        # since we turn the subject-IDs into 0 and 1, keep a mapping around\n",
        "        self.labeldict = {subid0:0, subid1:1} # give it subid, get class label\n",
        "        self.rlabeldict = {0:subid0, 1:subid1} # give class label, get subid\n",
        "        # label vector has self.n0 0s followed by self.n1 1s\n",
        "        self.label = np.array([0]*self.n0 + [1]*self.n1)\n",
        "        return\n",
        "\n",
        "    def __len__(self):\n",
        "        return self.n0 + self.n1\n",
        "    def __getitem__(self,idx):\n",
        "        return self.data[idx,:],self.label[idx]\n",
        "    def dimension(self):\n",
        "        assert self.data.shape[0] > 0, \"Error: no data\"\n",
        "        return self.data.shape[1]\n"
      ],
      "metadata": {
        "id": "Nij5-rDdemU9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 5. Define a single-linear-unit neural network class\n",
        "\n",
        "Here, we define a class `SingleNeuronNet` that we can instantiate, and we can train the instance.\n",
        "\n",
        "**Important terminology!** An instance of a network class is what we refer to as a `model`.\n",
        "\n",
        "The input size must be specified. It computes a biased linear function of a sample of the specified input size (that's what `nn.Linear` does) and feeds the result through a sigmoid function (`torch.sigmoid`). Recall that the sigmoid function asymptotically approaches 0 for negative numbers, asymptotically approaches +1 for positive numbers, and interpolates the origin. It's differentiable everywhere (which is critically important for backpropagation based training to work).  Note: the classic Perceptron's output is not differentiable everywhere, which means this is not going to train (or operate) exactly like a classically trained perceptron would."
      ],
      "metadata": {
        "id": "DpO8lG8jcO8p"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class SingleNeuronNet(nn.Module):\n",
        "    def __init__(self, input_size):\n",
        "        super(SingleNeuronNet, self).__init__()\n",
        "        # Define the single layer with input_size input features and 1 neuron\n",
        "        self.layer = nn.Linear(input_size, 1)\n",
        "\n",
        "    def forward(self, x):\n",
        "        # pass the input through this one layer and use the sigmoid to perform a\n",
        "        # soft thresholding (essentially estimating the probability that the sample\n",
        "        # is from class 1).\n",
        "        # Sigmoid saturates at 0 and 1, so if you are using it\n",
        "        # in a 2-class classifier, the class labels need to be 0 and 1!\n",
        "        output = torch.sigmoid(self.layer(x))\n",
        "        return output"
      ],
      "metadata": {
        "id": "ppU6y8X_Ocfl"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 6. Define an evaluation function\n",
        "\n",
        "If we have a model, and want to see how well it works on a 2-class classification task with data from a specified loader, this function can be used. It is specialized to this problem (two classes with class labels 0 and 1).\n",
        "\n",
        "You can call this function before training, to see how poorly your untrained model performs.  You can call it during training, to see how much better it gets as training proceeds. You can call it after training is done, to see the results at the end of training.\n",
        "\n",
        "It is risky to evaluate a model on its training data, as the results may be positively biased. But you can evaluate a model on validation data during training, to get a sense for the trend in performance on hopefully-independent data. And after training is done, you can evaluate the trained model on the testing data, yielding performance figures that you would report as the official \"performance\" of your model."
      ],
      "metadata": {
        "id": "iqSZp9qrLXXf"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def evaluate(model, loader):\n",
        "    # we need to switch the model into the evaluation mode - no gradients are calcaulated in this mode,\n",
        "    # so the model runs faster\n",
        "    model.eval()\n",
        "\n",
        "    # create a list to store the prediction correct-nesses\n",
        "    correct = []\n",
        "\n",
        "    # process all the data in the dataloader, in batches\n",
        "    for X,y in loader:\n",
        "        X = X.float()\n",
        "        y = y.float()\n",
        "        ypred = model(X)\n",
        "        # ypred is a \"probability of class 1\" - threshold it.\n",
        "        # .squeeze() de-nests it.\n",
        "        ypred = (ypred > 0.5).float().squeeze()\n",
        "        # if the prediction is correct, append True; else append False\n",
        "        #print(f'y {y} ypred {ypred}')\n",
        "        correct += (ypred == y).tolist()\n",
        "\n",
        "    # return the classification accuracy\n",
        "    acc = sum(correct)/len(correct)\n",
        "    return acc"
      ],
      "metadata": {
        "id": "JsUfTcSmoMpl"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 7. Training function\n",
        "\n",
        "Define a function that performs training of a supplied model, using suppled training data (via a DataLoader), for a specifid number of epochs and using a specified learning rate.\n",
        "\n",
        "This particular trainer makes some decisions for you: SGD optimizer and binary cross-entropy loss are the biggies.\n",
        "\n",
        "Usability note: see the use of `tqdm` in the training loop to produce a progress bar. An iteration of training can take some time, and (in general) if you're training for a lot of iterations, it might take minutes or hours or days or weeks or months or years (not kidding) for training to complete.  So some feedback that something is actually happening is useful."
      ],
      "metadata": {
        "id": "0TJbXOVRXYbO"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def train(model, train_loader, val_loader=[], epochs=100, learning_rate=0.001,debug=False):\n",
        "    \"\"\" train the model using data from the dataloader, for the specified\n",
        "    number of epochs and with the specified learning rate. \"\"\"\n",
        "\n",
        "    # good old stochastic gradient descent optimizer\n",
        "    optimizer = torch.optim.SGD(model.parameters(), lr=learning_rate)\n",
        "\n",
        "    # binary cross-entropy loss. The rule: if you used a sigmoid to generate\n",
        "    # the prediction (hence, class probability), use BCELoss. If you didn't\n",
        "    # (hence, logits instead of probabilities), use BCEWithLogitsLoss.\n",
        "    # The net above uses a Sigmoid in its output.\n",
        "    #\n",
        "    # This loss and the sigmoid make this net only an \"approximate\" perceptron.\n",
        "    # True perceptrons use hard thresholds and cannot be trained with gradient\n",
        "    # descent as performed in pytorch.\n",
        "\n",
        "    criterion = torch.nn.BCELoss()\n",
        "\n",
        "    model.train() # put model in training mode\n",
        "\n",
        "    running_losses = []\n",
        "    training_accuracies = []\n",
        "    if (val_loader): validation_accuracies = []\n",
        "\n",
        "    for epoch in tqdm.tqdm(range(epochs)):\n",
        "        optimizer.zero_grad()\n",
        "        running_loss = 0\n",
        "        for i,(X,y) in enumerate(train_loader):\n",
        "            # x,y are tensors: make sure they are floats, not doubles\n",
        "            X = X.float()\n",
        "            y = y.float().unsqueeze(1) # .unsqueeze() to match nested prediction\n",
        "            # run the net on X, get a y\n",
        "            ypredicted = model(X)\n",
        "            # calculate loss\n",
        "            loss = criterion(ypredicted,y)\n",
        "            # backpropagate the loss\n",
        "            loss.backward()\n",
        "            optimizer.step()\n",
        "            # accumulate loss, calc metrics\n",
        "            running_loss += loss.item()\n",
        "            train_acc = evaluate(model,train_loader)\n",
        "            if val_loader:\n",
        "                val_acc = evaluate(model,val_loader)\n",
        "        # update stats-by-epoch\n",
        "        running_losses.append(running_loss)\n",
        "        training_accuracies.append(train_acc)\n",
        "        if (val_loader): validation_accuracies.append(val_acc)\n",
        "        if debug:\n",
        "            print(f'epoch {epoch}')\n",
        "            print(f' training loss {running_loss}')\n",
        "            print(f' training accuracy, not that we should care: {train_acc}')\n",
        "            if val_loader:\n",
        "                print(f' Validation accuracy: {val_acc}')\n",
        "    if val_loader:\n",
        "        return [running_losses, training_accuracies, validation_accuracies]\n",
        "    else:\n",
        "        return [running_losses, training_accuracies]\n"
      ],
      "metadata": {
        "id": "RmQKplzSoRi3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 8. Finally: Run an experiment!\n",
        "\n",
        "Let's run a classification task on the data. In this cell, we\n",
        "\n",
        "1. Instantiate the data set and partition it into training, testing, and validation partitions\n",
        "  * Choose two people in the set of subjects and create a `TwoPersonData` from them.\n",
        "  * Then partition this into three pieces\n",
        "    * 60% for training\n",
        "    * 20% for validation\n",
        "    * 20% for testing\n",
        "\n",
        "    The partitioning will use random numbers, so we'll seed the random number generators also.\n",
        "\n",
        "2. Create `DataLoaders` for batches of training and testing data\n",
        "\n",
        "  The `DataLoader` is a generic means for *supplying the food* to the training and testing processes.  They wrap a `Dataset` or compatible data structure like the output of `random_split()` and provide means for getting \"batches\" of data from that dataset. IMHO, much of the value in the `DataLoader` is its utility when we explicitly separate the data based on its role, e.g. separate DataLoaders for train, test, and val.\n",
        "\n",
        "  We're creating a `DataLoader` for training, one for validation, and one for testing.\n",
        "\n",
        "3. Create an instance of the model.  `torchsummary.summary()` is a handy function to print out info about the model.  You have to supply the input shape as a tuple. Here, our input is a 128-D vector, so its input shape is the 1-element tuple `(128,)`.\n",
        "\n",
        "4. Train and test!"
      ],
      "metadata": {
        "id": "ZsHDCo7FoR75"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# assemble data from subjects 02463 and 04261 into a TwoPersonData set\n",
        "# instance\n",
        "\n",
        "twocdata = TwoPersonData(source=d,subid0='02463',subid1='04261')\n",
        "\n",
        "print(f'TwoPersonDataset() has {len(twocdata)} samples.')\n",
        "\n",
        "\n",
        "# split the data into training, validation, and testing partitions\n",
        "# (fractions must add up to 1.0)\n",
        "train_set_frac = 0.6\n",
        "val_set_frac = 0.2\n",
        "test_set_frac = 0.2\n",
        "train_set, val_set, test_set = torch.utils.data.random_split(twocdata,[train_set_frac,val_set_frac,test_set_frac])\n",
        "\n",
        "# how many samples and labels are issued when we iterate the DataLoader?\n",
        "batch_size = 8\n",
        "\n",
        "#create a DataLoader for each partition.\n",
        "\n",
        "train_loader = torch.utils.data.DataLoader(train_set, batch_size=batch_size, shuffle=True, drop_last=False)\n",
        "val_loader = torch.utils.data.DataLoader(val_set,shuffle=True, batch_size=batch_size, drop_last=False)\n",
        "test_loader = torch.utils.data.DataLoader(test_set,shuffle=True, batch_size=batch_size, drop_last=False)\n",
        "\n",
        "\n",
        "# create the model with number of inputs matching our data dimensionality.\n",
        "# and one neuron generating an output (class)\n",
        "\n",
        "model = SingleNeuronNet(twocdata.dimension())\n",
        "\n",
        "# print out a summary of the model we just created. You're required to supply\n",
        "# the size of the input to torchsummary.summary(). twocdata.dimension()\n",
        "# (defined above) is the size of a sample in the data\n",
        "# (128), and the input dimensionality is 1D (thus, a 128-dimensional vector).\n",
        "# In general, the input to a net can be any dimensionality you want, so\n",
        "# torchsummary.summary() required you to use a tuple for the input size, which\n",
        "# leads to the odd-looking 1D tuple (128,) here.\n",
        "\n",
        "torchsummary.summary(model,input_size=(twocdata.dimension(),))\n",
        "\n",
        "\n",
        "# hyperparameters - number of epochs of training\n",
        "num_epochs = 100\n",
        "# learning rate - set through experimentation (and experience)\n",
        "learning_rate = 0.01\n",
        "\n",
        "#train it\n",
        "[losses,tacc,vacc] = train(model,train_loader,val_loader=val_loader,epochs=num_epochs,learning_rate=learning_rate)\n",
        "\n",
        "# get performance on testing data\n",
        "test_acc = evaluate(model,test_loader)\n",
        "\n",
        "plt.plot(range(num_epochs),losses,'k-')\n",
        "plt.title('Running loss vs. epoch')\n",
        "plt.xlabel('Epoch')\n",
        "plt.ylabel('Training Loss')\n",
        "plt.show()\n",
        "\n",
        "\n",
        "plt.plot(range(num_epochs),tacc,'r-',label='Training Acc.')\n",
        "plt.plot(range(num_epochs),vacc,'g-',label='Validation Acc.')\n",
        "plt.scatter(num_epochs-1,test_acc,label=f'Testing Acc.: {test_acc:6.4f}',s=24,c='blue')\n",
        "plt.xlim(0,num_epochs)\n",
        "plt.ylim(0.0,1.0)\n",
        "plt.legend()\n",
        "plt.title('Accuracies')\n",
        "plt.xlabel('Epoch')\n",
        "plt.ylabel('Accuracy')"
      ],
      "metadata": {
        "id": "xouyfB9dO2a4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## What did we learn?\n",
        "\n",
        "1. Implementing and training a model has several parts:\n",
        " *   Creating a Dataset class and instantiating it\n",
        " *   Wrapping it in DataLoaders for training, validation, testing\n",
        " *   Creating a model class and instantiating it\n",
        " *   Defining functions for evaluation and training\n",
        " *   Training the model\n",
        " *   Estimating the trained model's performance (_on data **not** used to train it_!)\n",
        "\n",
        "2. There are lots of fiddly details in all of this (hence, this complete implementation - it's an example you can refer to in future practicals and assignments)\n",
        "\n",
        "3. In the experiment above, the model was trained to distinguish between two people and training got it to a place where it performed at an accuracy of 96%-99% (the number will change as you run the experiment multiple times - but probably not by much).\n",
        "\n"
      ],
      "metadata": {
        "id": "VBo06mUFF9_w"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Student Work\n"
      ],
      "metadata": {
        "id": "Hon1amcmSNRs"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Part 1. Shortish answer\n",
        "Answer these questions by placing text in the cell after the word \"Answer: \"\n",
        "\n",
        "1. The output of `torchsummary.summary()` in the code cell above indicates 129 parameters. Explain where the number 129 comes from for this network.\n",
        "\n",
        "STUDENT ANSWER GOES HERE\n",
        " Answer: The data has 128 dimensions and the bias has to be accounted for.  All together, this sums to 129 parameters.\n",
        "\n",
        "2. Reach back in time to the happy days of CSE30124 and explain why it might be likely for the training accuracy to exceed the testing accuracy in the second plot above.  You don't have to provide a mathematical discussion -- just explain what is going on and why.\n",
        "\n",
        "STUDENT ANSWER GOES HERE\n",
        " Answer: ***"
      ],
      "metadata": {
        "id": "wnfWHuzz9pMA"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Part 2. Ten Monte Carlo runs\n",
        "\n",
        "Copy the experiment code in the previous code cell to the cell below and modify it. This modified code needs to do several things:\n",
        " 3. Run the experiment with the same configuration **ten times**. Each run **must** use a separately created instance of the SingleNeuronNet model. Don't \"recycle\" the model from run to run.  Since the random numbers used to generate the splits are different, the experiments will all have different results. Sometimes, this is called a \"Monte Carlo experiment\". According to [Wikipedia](https://en.wikipedia.org/wiki/Monte_Carlo_method):\n",
        "> The name comes from the Monte Carlo Casino in Monaco, where the primary developer of the method, mathematician Stanis≈Çaw Ulam, was inspired by his uncle's gambling habits.\n",
        "\n",
        "\n",
        " 4. Compute and plot the _average_ training and validation accuracy, over the ten runs, as a function of epoch. Don't plot each run's accuracy curve; average them and plot the average.Also plot the _average_ testing performance as a single data point at epoch `num_epochs-1`. It is not necessary to plot the loss (average or otherwise) so you can remove the code that generates the loss plot. Summary: Your code should generate a single graph with an average training accuracy curve, an average validation accuracy curve, and an average test performance dot.\n",
        "\n",
        "Note: the ten-experiment run takes 5 minutes in my solution.\n"
      ],
      "metadata": {
        "id": "kIrr4QtjTJ_q"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# PRACTICAL CODE GOES HERE!\n",
        "\n"
      ],
      "metadata": {
        "id": "7gVvQ9HyVFsH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Part 3 - A bigger experiment\n",
        "\n",
        "The previous experiments used data from only two subjects of the many in the data file provided. Let's look at more subjects.\n",
        "\n",
        "5. In the code cell below, filter the dictionary `d` to create a new dictionary `d2`, containing those entries ((`key`, `value`) pairs) where the number of samples for the subject specified by `key` is greater than or equal to 100.\n",
        "\n",
        "Hints:\n",
        " * `len(d)` is the number of keys in `d`\n",
        " * `len(d[k])` is the number of samples for the subject `k`\n",
        " * a dictionary comprehension with an `if` clause can make this a _very_ short piece of code.\n"
      ],
      "metadata": {
        "id": "VumxI1dRVGo9"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# PRACTICAL CODE GOES HERE!\n",
        "\n"
      ],
      "metadata": {
        "id": "gqg4f7M3YMbl"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "6. Copy the original provided experiment code to the cell below, and modicy it to perform ten training and evaluation experiments.\n",
        " * For each of the ten experiments, choose a _distinct pair of subjects_ (keys) from `d2` created above) to create the dataset that is provided to the dataloaders. Leave all of the other parameters unchanged.\n",
        " * Generate three output plots.\n",
        "  * One is a plot of training loss for each pair of subjects (10 curves on this plot)\n",
        "  * One is a plot of training accuracy for each pair of subjects (10 more curves)\n",
        "  * One is a plot of validation accuracy for each pair of subjects (10 more curves). On this plot, also plot the testing accuracy for each pair as a dot at epoch `num_epochs-1` (ten dots).\n",
        " Use a legend, and label each curve and dot with the string \"subjectID1-vs-subjectID2\", (e.g. \"04203-vs-04459\"), and make sure each experiment uses a different color so your grader can tell the experiments apart.\n",
        "\n",
        " Note: this experiment took five minutes in the prof's implementation.\n",
        "\n",
        "7. Immediately below, comment on the results you obtained in this experiment.  Did they show some consistency in behavior, or were they very different in performance? Since you know that these samples came from face images of different people, what might cause differences in performance?\n",
        "\n",
        "Answer: STUDENT ANSWER GOES HERE\n"
      ],
      "metadata": {
        "id": "kdm1cPyTYLOV"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# PRACTICAL CODE GFOES HERE\n"
      ],
      "metadata": {
        "id": "vfq1AkuMPGgA"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}